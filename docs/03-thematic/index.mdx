
# 专题分析

import OpenDiggerBumpChart from '@site/src/components/OpenDiggerBumpChart';
import { MetricCategory, RepositoryMetricType, TimeUnit } from '@site/src/types/opendigger';

## LLM Agent 框架生态系统

大型语言模型（LLM）Agent 框架已成为 AI 生态系统中的关键组成部分，使开发人员能够以结构化和高效的方式构建利用 LLM 能力的复杂应用程序。以下是 2023-2025 年期间主要 LLM Agent 框架的 OpenRank 排名动态变化。

### OpenRank 月度排名赛跑图 (2023-04 ~ 2025-04)

下面的动态排名图展示了主要 LLM Agent 框架的 OpenRank 月度排名变化。通过点击"播放"按钮，您可以观察各框架排名的动态变化，直观地了解生态系统的演变过程。时间轴滑块允许您手动探索特定时间点的排名数据，动画效果平滑流畅，帮助您更清晰地把握框架间的竞争态势。

<OpenDiggerBumpChart
  type={[MetricCategory.REPOSITORY, RepositoryMetricType.OPENRANK]}
  names={[
    'langgenius/dify',
    'n8n-io/n8n',
    'infiniflow/ragflow',
    'langchain-ai/langchain',
    'run-llama/llama_index',
    'microsoft/autogen',
    'microsoft/semantic-kernel',
    'labring/FastGPT',
    'langchain-ai/langgraph',
    'crewAIInc/crewAI'
  ]}
  timeUnit={TimeUnit.MONTH}
  timeSpan={['2023-04','2025-04']}
  height="700px"
/>

从这个动态可视化中，我们可以清晰地观察到：

1. **领导地位的变化**：从 2023 年初至 2025 年，LLM Agent 框架生态系统中的主导地位经历了显著变化，展示了该领域的竞争活力。
2. **新兴力量崛起**：如 Dify、RAGFlow 等新兴框架迅速崛起，表明该领域持续创新。
3. **市场动态**：框架之间的相对排名频繁变化，反映了这个快速发展领域的激烈竞争和创新步伐。
4. **技术路线多元化**：从单一工具向专业化、垂直领域发展，满足不同场景需求。

此动态排名图不仅展示了各框架的发展轨迹，还揭示了整个 LLM Agent 生态系统的演变规律，为企业和开发者提供了宝贵的技术选型参考。

## LLM 模型服务生态系统

随着大型语言模型的广泛应用，高效的推理引擎和部署服务成为 AI 产业的关键技术基础设施。推理引擎负责优化模型部署、提升推理速度、降低资源消耗，对于 AI 应用的规模化落地具有决定性作用。以下是 2023-2025 年期间主要 LLM 推理引擎项目的 OpenRank 排名动态变化。

### OpenRank 月度排名赛跑图 (2023-01 ~ 2025-04)

下面的动态排名图展示了主要 LLM 推理引擎项目的 OpenRank 月度排名变化。通过点击"播放"按钮，您可以观察各项目排名的动态变化，直观地了解推理引擎技术赛道的演变过程。时间轴滑块允许您手动探索特定时间点的排名数据，动画效果平滑流畅，帮助您更清晰地把握推理引擎技术的竞争格局。

<OpenDiggerBumpChart
  type={[MetricCategory.REPOSITORY, RepositoryMetricType.OPENRANK]}
  names={[
    'vllm-project/vllm',
    'ollama/ollama',
    'sgl-project/sglang',
    'ggml-org/llama.cpp',
    'microsoft/onnxruntime',
    'NVIDIA/TensorRT-LLM',
    'kvcache-ai/ktransformers',
    'InternLM/lmdeploy',
    'xorbitsai/inference',
    'ai-dynamo/dynamo'
  ]}
  timeUnit={TimeUnit.MONTH}
  timeSpan={['2023-04','2025-04']}
  height="700px"
/>

从这个动态可视化中，我们可以清晰地观察到 LLM 推理引擎生态系统的几个关键特征和趋势：

1. **多元化技术路线共存**：从 CPU 优化（llama.cpp）到 GPU 高性能推理（vLLM、TensorRT-LLM）再到本地部署方案（Ollama），多种技术路线共同发展，满足不同应用场景的推理需求。

2. **开源领军项目的崛起**：如 vLLM、Ollama 和 llama.cpp 等项目迅速崛起，展现了社区驱动的技术创新活力，这些项目在各自领域形成了明显的技术优势。

3. **商业与开源协同发展**：微软的 ONNX Runtime 和 NVIDIA 的 TensorRT-LLM 等商业支持的项目与纯社区项目形成良性竞争与互补，共同推动了整个生态的繁荣。

4. **专业化趋势明显**：从通用推理框架向特定场景优化的专业化方向发展，不同项目在推理速度、显存优化、量化技术等方面各有侧重。

5. **技术迭代加速**：新项目（如 sglang、ktransformers）能够在短时间内快速成长并获得关注，表明推理技术创新正在不断加速。

推理引擎作为 LLM 应用的"最后一公里"，其性能直接影响用户体验和部署成本。这一领域的竞争态势表明，随着大模型应用场景的不断扩展，推理技术的优化空间和创新潜力仍然巨大。企业在选择推理引擎时，需要根据自身应用场景、硬件环境和性能需求，在这些技术方案中做出合适的选择。

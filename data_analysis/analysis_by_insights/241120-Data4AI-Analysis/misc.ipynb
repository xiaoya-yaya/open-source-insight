{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查询 22、23、24 年大数据领域项目 Top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('big_data_projects_full.csv')\n",
    "repo_names = df['repository'].tolist()\n",
    "\n",
    "# 获取每个 repo_name 的 openrank 数据\n",
    "def get_openrank_data(repo_name):\n",
    "  url = f'https://oss.x-lab.info/open_digger/github/{repo_name}/openrank.json'\n",
    "  response = requests.get(url)\n",
    "  if response.status_code == 200:\n",
    "    return response.json()\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "# 存储所有项目的 openrank 数据\n",
    "openrank_data = {}\n",
    "for repo_name in repo_names:\n",
    "  data = get_openrank_data(repo_name)\n",
    "  if data:\n",
    "    openrank_data[repo_name] = data\n",
    "\n",
    "# 获取每一年排名 Top 20 的项目\n",
    "def get_top_projects(year):\n",
    "  projects = []\n",
    "  for repo_name, data in openrank_data.items():\n",
    "    if str(year) in data:\n",
    "      projects.append((repo_name, data[str(year)]))\n",
    "  projects.sort(key=lambda x: x[1], reverse=True)\n",
    "  return projects[:20]\n",
    "\n",
    "# # 打印出 2022、2023、2024 年每一年排名 Top 20 的项目和对应的值\n",
    "# for year in [2022, 2023, 2024]:\n",
    "#   top_projects = get_top_projects(year)\n",
    "#   print(f\"Top 20 projects for {year}:\")\n",
    "#   for repo_name, value in top_projects:\n",
    "#     print(f\"{repo_name}: {value}\")\n",
    "#   print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取 2022、2023、2024 年的 openrank 数据\n",
    "openrank_2022 = {repo_name: data['2022'] for repo_name, data in openrank_data.items() if '2022' in data}\n",
    "openrank_2023 = {repo_name: data['2023'] for repo_name, data in openrank_data.items() if '2023' in data}\n",
    "openrank_2024 = {repo_name: data['2024'] for repo_name, data in openrank_data.items() if '2024' in data}\n",
    "\n",
    "# 将 2022、2023、2024 年的 openrank 数据添加到 DataFrame 中\n",
    "df['openrank_2022'] = df['repository'].map(openrank_2022)\n",
    "df['openrank_2023'] = df['repository'].map(openrank_2023)\n",
    "df['openrank_2024'] = df['repository'].map(openrank_2024)\n",
    "\n",
    "# 保存更新后的 DataFrame 到 CSV 文件\n",
    "df.to_csv('big_data_projects_full.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据输入的 repo 列表，拼接项目的 GitHub url 地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('temp_projects.csv')\n",
    "repo_list = df['repo_name'].tolist()\n",
    "# 根据输入的 repo 列表，拼接出对应的 url，并保存到 top_projects.csv 文件中\n",
    "def get_repo_info(repo_list):\n",
    "    repo_info = []\n",
    "    for repo in repo_list:\n",
    "        repo_info.append('https://github.com/' + repo)\n",
    "    return repo_info\n",
    "df['repo_url'] = get_repo_info(repo_list)\n",
    "df.to_csv('temp_projects.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从 json 文件中读数据，保存到 csv 文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 top_projects_labels.json 中读取数据，将 repo_name 和 labels 保存到 top_projects.csv 中\n",
    "df = pd.read_csv('top_projects.csv')\n",
    "repo_names = df['repo_name'].tolist()\n",
    "with open('top_projects_labels.json', 'r', encoding='utf-8') as f:\n",
    "  data = json.load(f)\n",
    "# 查找每个 repo_name 对应的 label\n",
    "all_labels = []\n",
    "for repo_name in repo_names:\n",
    "  labels = []\n",
    "  for project in data:\n",
    "    if project[0] == repo_name:\n",
    "      for label in project[1]:\n",
    "        labels.append(label['name'])\n",
    "      break\n",
    "  all_labels.append(labels)\n",
    "\n",
    "all_labels_str = ['; '.join(map(str, labels)) for labels in all_labels]\n",
    "df['labels'] = all_labels_str\n",
    "  \n",
    "df.to_csv('top_projects.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过滤 nix 家族的项目节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 读取 JSON 文件\n",
    "with open('graph_data4ai.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 确保 data 是一个字典\n",
    "if isinstance(data, list):\n",
    "    data = data[0]\n",
    "\n",
    "# 过滤 nodes\n",
    "filtered_nodes = [node for node in data['nodes'] if 'nix-community' not in node[0] and 'NixOS' not in node[0]]\n",
    "\n",
    "# 过滤 edges\n",
    "filtered_edges = [edge for edge in data['edges'] if 'nix-community' not in edge[0] and 'nix-community' not in edge[1] and 'NixOS' not in edge[0] and 'NixOS' not in edge[1]]\n",
    "\n",
    "# 更新数据\n",
    "data['nodes'] = filtered_nodes\n",
    "data['edges'] = filtered_edges\n",
    "\n",
    "# 写回 JSON 文件\n",
    "with open('graph_data4ai.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(\"过滤完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

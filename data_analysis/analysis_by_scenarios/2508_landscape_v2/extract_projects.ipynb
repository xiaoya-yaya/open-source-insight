{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c947852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import clickhouse_connect\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import json\n",
    "load_dotenv()\n",
    "clickhouse_host = os.getenv(\"CLICKHOUSE_HOST\")\n",
    "username = os.getenv(\"CLICKHOUSE_USER\")\n",
    "password = os.getenv(\"CLICKHOUSE_PASSWORD\")\n",
    "github_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "client = clickhouse_connect.get_client(host=clickhouse_host, port=8123, username=username, password=password)\n",
    "\n",
    "headers = {\n",
    "  \"Authorization\": f\"token {github_token}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc98d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 v1 和 v2 的数据\n",
    "df_v1 = pd.read_csv('landscapev1.csv', encoding='utf-8-sig')\n",
    "df_v2 = pd.read_csv('landscapev2.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 找出在 v1 中但不在 v2 中的 repo_id\n",
    "v1_repo_ids = set(df_v1['repo_id'])\n",
    "v2_repo_ids = set(df_v2['repo_id'])\n",
    "missing_repo_ids = v1_repo_ids - v2_repo_ids\n",
    "\n",
    "# 对于每个缺失的 repo_id，从 v1 中获取对应的数据并添加到 v2\n",
    "new_rows = []\n",
    "for repo_id in missing_repo_ids:\n",
    "    v1_row = df_v1[df_v1['repo_id'] == repo_id].iloc[0]\n",
    "    new_row = {\n",
    "        'repo_id': v1_row['repo_id'],\n",
    "        'repo_name': v1_row['repo_name'],\n",
    "        'classification': v1_row['classification']\n",
    "    }\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# 将新行添加到 v2 中\n",
    "if new_rows:\n",
    "    df_new = pd.DataFrame(new_rows)\n",
    "    df_v2 = pd.concat([df_v2, df_new], ignore_index=True)\n",
    "    \n",
    "# 保存更新后的 v2 数据\n",
    "df_v2.to_csv('landscape.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262f05c7",
   "metadata": {},
   "source": [
    "## 获取 Landscape 所需的 GitHub 仓库信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf35e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # Import requests for making API calls\n",
    "\n",
    "# List of repositories to fetch\n",
    "repo_names = pd.read_csv('landscape.csv')['repo_name'].tolist()\n",
    "\n",
    "repo_data = []  # Initialize empty list for repo data\n",
    "# fetch stars, language and descripiton through repo_name\n",
    "def fetch_repo_info(repo_names, headers):\n",
    "  github_repo_url = \"https://api.github.com/repos/\"\n",
    "  openrank_repo_url = \"https://oss.open-digger.cn/github/{repo_name}/openrank.json\"\n",
    "  for repo_name in repo_names:\n",
    "    response = requests.get(github_repo_url + repo_name, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "      data = response.json()\n",
    "      repo_id = data['id']\n",
    "      stars = data['stargazers_count'] \n",
    "      forks = data['forks_count']\n",
    "      language = data['language']\n",
    "      created_at = data['created_at'].split(\"T\")[0]\n",
    "      description = data['description']\n",
    "      topics = ','.join(data.get(\"topics\", [])) # 将topics列表转换为逗号分隔的字符串\n",
    "      # avatar_url = data['owner']['avatar_url']\n",
    "      openrank_url = openrank_repo_url.format(repo_name=repo_name)\n",
    "      openrank_response = requests.get(openrank_url)\n",
    "      if openrank_response.status_code == 200:\n",
    "        openrank_json = openrank_response.json()\n",
    "        openrank = openrank_json.get(\"2025-07\")\n",
    "      else:\n",
    "        openrank = None\n",
    "      \n",
    "      repo_data.append({\n",
    "        'repo_id': repo_id,\n",
    "        'repo_name': repo_name,\n",
    "        'stars': stars,\n",
    "        'forks': forks, \n",
    "        'openrank_25': round(openrank) if openrank else None,\n",
    "        'language': language,\n",
    "        'created_at': created_at,\n",
    "        'description': description,\n",
    "        'topics': topics\n",
    "      })\n",
    "    else:\n",
    "      print(f\"Failed to fetch data for {repo_name}\")\n",
    "  \n",
    "  return repo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc59e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for sourcegraph/cody\n",
      "Repository data saved to repository_data.csv\n"
     ]
    }
   ],
   "source": [
    "repo_data = fetch_repo_info(repo_names, headers)\n",
    "\n",
    "# Save the repository data to CSV file\n",
    "repo_df = pd.DataFrame(repo_data)\n",
    "if not repo_df.empty:\n",
    "    repo_df.to_csv('repository_data.csv', index=False)\n",
    "    print(f\"Repository data saved to repository_data.csv\")\n",
    "else:\n",
    "    print(\"No repository data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70783f26",
   "metadata": {},
   "source": [
    "## 获取 OpenRank > 50 的项目列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811fae5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe46615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 查询 github openrank>50 top 项目列表\n",
    "def execute_query_top_openrank(created_at='2025-01-01'):\n",
    "  sql_query_top_openrank = \"\"\"\n",
    "    SELECT\n",
    "        repo_id,\n",
    "        repo_name,\n",
    "        ROUND(AVG(openrank)) AS avg_openrank_25\n",
    "    FROM\n",
    "        opensource.global_openrank\n",
    "    WHERE\n",
    "        platform = 'GitHub' AND\n",
    "        created_at >= %s\n",
    "    GROUP BY\n",
    "        repo_id, repo_name\n",
    "    HAVING\n",
    "        avg_openrank_25 >= 30 and avg_openrank_25 < 50\n",
    "    ORDER BY\n",
    "        avg_openrank_25 DESC\n",
    "\n",
    "  \"\"\"\n",
    "  formatted_query = sql_query_top_openrank % (f\"'{created_at}'\")\n",
    "  results = client.query(formatted_query)\n",
    "  return results\n",
    "\n",
    "\n",
    "results_openrank = execute_query_top_openrank()\n",
    "print(f\"Found {len(results_openrank.result_rows)} repositories with high OpenRank scores\")\n",
    "\n",
    "# 提取项目名称到列表\n",
    "repo_names = [row[1] for row in results_openrank.result_rows]\n",
    "print(f\"First 5 repositories: {repo_names[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bee69c",
   "metadata": {},
   "source": [
    "## 添加项目基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def get_repo_info(repo_name, headers):\n",
    "    \n",
    "    url = f\"https://api.github.com/repos/{repo_name}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Process and return the data\n",
    "        return {\n",
    "            \"id\": data[\"id\"],\n",
    "            \"repo_name\": data[\"full_name\"],\n",
    "            \"stargazers_count\": data[\"stargazers_count\"],\n",
    "            \"forks_count\": data[\"forks_count\"],\n",
    "            \"language\": data[\"language\"],\n",
    "            \"created_at\": data[\"created_at\"],\n",
    "            \"description\": data[\"description\"],\n",
    "            \"topics\": data.get(\"topics\", [])\n",
    "        }\n",
    "\n",
    "results = []\n",
    "\n",
    "for repo_name in repo_names:\n",
    "  print(f\"Processing {repo_name}...\")\n",
    "  \n",
    "  # Get repo info from GitHub API\n",
    "  repo_info = get_repo_info(repo_name, headers)\n",
    "  \n",
    "  if repo_info:\n",
    "        \n",
    "    # Compile all information\n",
    "    result = {\n",
    "      \"repo_id\": repo_info[\"id\"],\n",
    "      \"repo_name\": repo_info[\"repo_name\"],\n",
    "      \"stars\": repo_info[\"stargazers_count\"],\n",
    "      \"forks\": repo_info[\"forks_count\"],\n",
    "      \"language\": repo_info[\"language\"],\n",
    "      \"created_at\": repo_info[\"created_at\"].split(\"T\")[0],\n",
    "      \"description\": repo_info[\"description\"],\n",
    "      \"topics\": \", \".join(repo_info.get(\"topics\", [])) if repo_info.get(\"topics\") else \"\"\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "  else:\n",
    "    print(f\"Failed to get info for {repo_name}\")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "columns_order = [\"repo_id\", \"repo_name\", \"stars\", \"forks\", \"language\", \"created_at\", \"description\", 'topics']\n",
    "df_results = df_results[columns_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf9033b",
   "metadata": {},
   "source": [
    "## 添加 OpenRank 值并存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54772ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract repo_id and avg_openrank from the results_openrank\n",
    "repo_id_avg_openrank = {row[1]: (row[0], row[2]) for row in results_openrank.result_rows}\n",
    "\n",
    "# Initialize new columns with None values\n",
    "df_results['repo_id'] = None\n",
    "df_results['avg_openrank_25'] = None\n",
    "\n",
    "# Fill in the values for repo_id and avg_openrank_25\n",
    "for idx, repo_name in enumerate(df_results['repo_name']):\n",
    "  if repo_name in repo_id_avg_openrank:\n",
    "    df_results.at[idx, 'repo_id'] = repo_id_avg_openrank[repo_name][0]\n",
    "    df_results.at[idx, 'avg_openrank_25'] = repo_id_avg_openrank[repo_name][1]\n",
    "\n",
    "# Update columns order to include the new columns\n",
    "columns_order = columns_order + ['repo_id', 'avg_openrank_25']\n",
    "df_results_new = df_results[columns_order]\n",
    "\n",
    "csv_filename = f\"repo_info_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "df_results_new.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Successfully processed {len(results)} repositories\")\n",
    "print(f\"Results saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5712a0",
   "metadata": {},
   "source": [
    "## 标注出已有的项目和相应的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files with explicit encoding\n",
    "landscape_full = pd.read_csv('landscape-full-08.csv')\n",
    "landscape527 = pd.read_csv('landscape527_full.csv')\n",
    "\n",
    "print(f\"Loaded landscape-full-08.csv with {landscape_full.shape[0]} entries\")\n",
    "print(f\"Loaded landscape527_full.csv with {landscape527.shape[0]} entries\")\n",
    "\n",
    "# Check the column names\n",
    "print(\"\\nColumns in landscape-full-08.csv:\")\n",
    "print(landscape_full.columns.tolist())\n",
    "print(\"\\nColumns in landscape527_full.csv:\")\n",
    "print(landscape527.columns.tolist())\n",
    "\n",
    "# Create a mapping from repo_name to classification in landscape527\n",
    "classification_map = {}\n",
    "for _, row in landscape527.iterrows():\n",
    "  if 'repo_name' in landscape527.columns and 'classification' in landscape527.columns:\n",
    "    repo_name = row['repo_name']\n",
    "    classification = row['classification']\n",
    "    if pd.notna(repo_name) and pd.notna(classification):\n",
    "      classification_map[repo_name] = classification\n",
    "\n",
    "# Update the llm field in landscape_full with classifications from landscape527\n",
    "matches = 0\n",
    "for idx, row in landscape_full.iterrows():\n",
    "  if row['repo_name'] in classification_map:\n",
    "    landscape_full.at[idx, 'llm'] = classification_map[row['repo_name']]\n",
    "    matches += 1\n",
    "\n",
    "# Save the updated dataframe\n",
    "output_file = 'landscape_full_updated.csv'\n",
    "landscape_full.to_csv(output_file, index=False)\n",
    "print(f\"Updated dataframe saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ce6b5",
   "metadata": {},
   "source": [
    "## 获取 Star 数 Top 1K 的 Rust 项目信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e762eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# GitHub API endpoint\n",
    "api_url = \"https://api.github.com/search/repositories\"\n",
    "\n",
    "# 设置请求头,需要替换为你的GitHub token\n",
    "headers = {\n",
    "    \"Accept\": \"application/vnd.github.v3+json\",\n",
    "    # \"Authorization\": \"token YOUR_GITHUB_TOKEN\"  # 如果需要更高的API限制,请取消注释并填入token\n",
    "}\n",
    "\n",
    "# 搜索参数 - 专门搜索Rust语言的项目\n",
    "params = {\n",
    "    \"q\": \"language:rust\",  # 指定搜索Rust语言的仓库\n",
    "    \"sort\": \"stars\",       # 按star数排序\n",
    "    \"order\": \"desc\",       # 降序排列\n",
    "    \"per_page\": 100       # 每页100条结果\n",
    "}\n",
    "\n",
    "all_repos = []\n",
    "pages = 10  # 获取10页,总共1000个仓库\n",
    "\n",
    "for page in range(1, pages + 1):\n",
    "    try:\n",
    "        params[\"page\"] = page\n",
    "        response = requests.get(api_url, headers=headers, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            repos = data[\"items\"]\n",
    "            \n",
    "            for repo in repos:\n",
    "                repo_data = {\n",
    "                    \"repo_name\": f\"{repo['owner']['login']}/{repo['name']}\",\n",
    "                    \"stars\": repo[\"stargazers_count\"],\n",
    "                    \"forks\": repo[\"forks_count\"],\n",
    "                    \"created_at\": repo[\"created_at\"],\n",
    "                    \"description\": repo[\"description\"],\n",
    "                    \"topics\": \",\".join(repo.get(\"topics\", []))\n",
    "                }\n",
    "                all_repos.append(repo_data)\n",
    "            \n",
    "            print(f\"成功获取第 {page} 页数据，当前已获取 {len(all_repos)} 个仓库\")\n",
    "            \n",
    "            # 检查是否还有更多数据\n",
    "            if len(repos) < 100:\n",
    "                print(\"已获取所有可用数据\")\n",
    "                break\n",
    "                \n",
    "            sleep(2)  # 避免触发API限制\n",
    "            \n",
    "        else:\n",
    "            print(f\"获取第 {page} 页数据失败: {response.status_code}\")\n",
    "            if response.status_code == 403:\n",
    "                print(\"可能达到API访问限制，请稍后再试或使用GitHub Token\")\n",
    "            break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"处理第 {page} 页时发生错误: {str(e)}\")\n",
    "        break\n",
    "\n",
    "# 转换为DataFrame并保存\n",
    "top_repos_df = pd.DataFrame(all_repos)\n",
    "output_file = \"top_rust_repos.csv\"\n",
    "top_repos_df.to_csv(output_file, index=False)\n",
    "print(f\"已保存 {len(all_repos)} 个Rust仓库信息到 {output_file}\")\n",
    "\n",
    "# 显示前10个仓库的基本信息\n",
    "print(\"\\n前10个最受欢迎的Rust仓库:\")\n",
    "print(top_repos_df[[\"repo_name\", \"stars\", \"forks\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3c3bd",
   "metadata": {},
   "source": [
    "获取 OpenRank 2025 Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfdf370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功获取 pytorch/pytorch 的OpenRank趋势数据\n",
      "成功获取 vllm-project/vllm 的OpenRank趋势数据\n",
      "成功获取 langgenius/dify 的OpenRank趋势数据\n",
      "成功获取 tenstorrent/tt-metal 的OpenRank趋势数据\n",
      "成功获取 microsoft/vscode-copilot-release 的OpenRank趋势数据\n",
      "成功获取 huggingface/transformers 的OpenRank趋势数据\n",
      "成功获取 CherryHQ/cherry-studio 的OpenRank趋势数据\n",
      "成功获取 sgl-project/sglang 的OpenRank趋势数据\n",
      "成功获取 ollama/ollama 的OpenRank趋势数据\n",
      "成功获取 apache/doris 的OpenRank趋势数据\n",
      "成功获取 apache/airflow 的OpenRank趋势数据\n",
      "成功获取 openvinotoolkit/openvino 的OpenRank趋势数据\n",
      "成功获取 BerriAI/litellm 的OpenRank趋势数据\n",
      "成功获取 open-webui/open-webui 的OpenRank趋势数据\n",
      "成功获取 ggml-org/llama.cpp 的OpenRank趋势数据\n",
      "成功获取 ray-project/ray 的OpenRank趋势数据\n",
      "成功获取 n8n-io/n8n 的OpenRank趋势数据\n",
      "成功获取 ultralytics/ultralytics 的OpenRank趋势数据\n",
      "成功获取 PaddlePaddle/Paddle 的OpenRank趋势数据\n",
      "成功获取 infiniflow/ragflow 的OpenRank趋势数据\n",
      "成功获取 pytorch/executorch 的OpenRank趋势数据\n",
      "成功获取 airbytehq/airbyte 的OpenRank趋势数据\n",
      "成功获取 NVIDIA/NeMo 的OpenRank趋势数据\n",
      "成功获取 microsoft/onnxruntime 的OpenRank趋势数据\n",
      "成功获取 supabase/supabase 的OpenRank趋势数据\n",
      "成功获取 stackblitz/bolt.new 的OpenRank趋势数据\n",
      "成功获取 apache/spark 的OpenRank趋势数据\n",
      "成功获取 continuedev/continue 的OpenRank趋势数据\n",
      "成功获取 langflow-ai/langflow 的OpenRank趋势数据\n",
      "成功获取 elizaOS/eliza 的OpenRank趋势数据\n",
      "成功获取 lobehub/lobe-chat 的OpenRank趋势数据\n",
      "成功获取 cline/cline 的OpenRank趋势数据\n",
      "成功获取 milvus-io/milvus 的OpenRank趋势数据\n",
      "成功获取 comfyanonymous/ComfyUI 的OpenRank趋势数据\n",
      "成功获取 NVIDIA/TensorRT-LLM 的OpenRank趋势数据\n",
      "成功获取 langchain-ai/langchain 的OpenRank趋势数据\n",
      "成功获取 huggingface/diffusers 的OpenRank趋势数据\n",
      "成功获取 anthropics/claude-code 的OpenRank趋势数据\n",
      "成功获取 apache/iceberg 的OpenRank趋势数据\n",
      "成功获取 All-Hands-AI/OpenHands 的OpenRank趋势数据\n",
      "成功获取 hiyouga/LLaMA-Factory 的OpenRank趋势数据\n",
      "成功获取 volcengine/verl 的OpenRank趋势数据\n",
      "成功获取 opensearch-project/OpenSearch 的OpenRank趋势数据\n",
      "成功获取 open-metadata/OpenMetadata 的OpenRank趋势数据\n",
      "成功获取 triton-lang/triton 的OpenRank趋势数据\n",
      "成功获取 vercel/ai 的OpenRank趋势数据\n",
      "成功获取 run-llama/llama_index 的OpenRank趋势数据\n",
      "成功获取 modelscope/ms-swift 的OpenRank趋势数据\n",
      "成功获取 unslothai/unsloth 的OpenRank趋势数据\n",
      "成功获取 Aider-AI/aider 的OpenRank趋势数据\n",
      "成功获取 microsoft/semantic-kernel 的OpenRank趋势数据\n",
      "成功获取 google/adk-python 的OpenRank趋势数据\n",
      "成功获取 block/goose 的OpenRank趋势数据\n",
      "成功获取 browser-use/browser-use 的OpenRank趋势数据\n",
      "成功获取 pydantic/pydantic-ai 的OpenRank趋势数据\n",
      "成功获取 streamlit/streamlit 的OpenRank趋势数据\n",
      "成功获取 datahub-project/datahub 的OpenRank趋势数据\n",
      "成功获取 jax-ml/jax 的OpenRank趋势数据\n",
      "成功获取 mlflow/mlflow 的OpenRank趋势数据\n",
      "成功获取 agno-agi/agno 的OpenRank趋势数据\n",
      "成功获取 microsoft/autogen 的OpenRank趋势数据\n",
      "成功获取 danny-avila/LibreChat 的OpenRank趋势数据\n",
      "成功获取 ai-dynamo/dynamo 的OpenRank趋势数据\n",
      "成功获取 langchain-ai/langgraph 的OpenRank趋势数据\n",
      "成功获取 gradio-app/gradio 的OpenRank趋势数据\n",
      "成功获取 spring-projects/spring-ai 的OpenRank趋势数据\n",
      "成功获取 siyuan-note/siyuan 的OpenRank趋势数据\n",
      "成功获取 apache/hudi 的OpenRank趋势数据\n",
      "成功获取 livekit/agents 的OpenRank趋势数据\n",
      "成功获取 labring/FastGPT 的OpenRank趋势数据\n",
      "成功获取 mastra-ai/mastra 的OpenRank趋势数据\n",
      "成功获取 scikit-learn/scikit-learn 的OpenRank趋势数据\n",
      "成功获取 modelcontextprotocol/servers 的OpenRank趋势数据\n",
      "成功获取 kvcache-ai/ktransformers 的OpenRank趋势数据\n",
      "成功获取 AI-Hypercomputer/maxtext 的OpenRank趋势数据\n",
      "成功获取 PrefectHQ/prefect 的OpenRank趋势数据\n",
      "成功获取 wandb/wandb 的OpenRank趋势数据\n",
      "成功获取 apache/gravitino 的OpenRank趋势数据\n",
      "成功获取 apache/paimon 的OpenRank趋势数据\n",
      "成功获取 mannaandpoem/OpenManus 的OpenRank趋势数据\n",
      "成功获取 yetone/avante.nvim 的OpenRank趋势数据\n",
      "成功获取 iree-org/iree 的OpenRank趋势数据\n",
      "成功获取 marimo-team/marimo 的OpenRank趋势数据\n",
      "成功获取 HumanSignal/label-studio 的OpenRank趋势数据\n",
      "成功获取 langfuse/langfuse 的OpenRank趋势数据\n",
      "成功获取 modular/modular 的OpenRank趋势数据\n",
      "成功获取 weaviate/weaviate 的OpenRank趋势数据\n",
      "成功获取 crewAIInc/crewAI 的OpenRank趋势数据\n",
      "成功获取 1Panel-dev/MaxKB 的OpenRank趋势数据\n",
      "成功获取 NVIDIA/cccl 的OpenRank趋势数据\n",
      "成功获取 rapidsai/cudf 的OpenRank趋势数据\n",
      "成功获取 opencv/opencv 的OpenRank趋势数据\n",
      "成功获取 intel/intel-xpu-backend-for-triton 的OpenRank趋势数据\n",
      "成功获取 camel-ai/camel 的OpenRank趋势数据\n",
      "成功获取 chroma-core/chroma 的OpenRank趋势数据\n",
      "成功获取 ROCm/composable_kernel 的OpenRank趋势数据\n",
      "成功获取 intel/ipex-llm 的OpenRank趋势数据\n",
      "成功获取 tensorflow/tensorflow 的OpenRank趋势数据\n",
      "成功获取 firebase/genkit 的OpenRank趋势数据\n",
      "成功获取 1Panel-dev/1Panel 的OpenRank趋势数据\n",
      "成功获取 Azure/AgentBaker 的OpenRank趋势数据\n",
      "成功获取 delta-io/delta 的OpenRank趋势数据\n",
      "成功获取 openai/openai-agents-python 的OpenRank趋势数据\n",
      "成功获取 xinnan-tech/xiaozhi-esp32-server 的OpenRank趋势数据\n",
      "成功获取 xorbitsai/inference 的OpenRank趋势数据\n",
      "成功获取 huggingface/optimum-habana 的OpenRank趋势数据\n",
      "成功获取 Mintplex-Labs/anything-llm 的OpenRank趋势数据\n",
      "成功获取 openxla/xla 的OpenRank趋势数据\n",
      "成功获取 google-gemini/gemini-cli 的OpenRank趋势数据\n",
      "成功获取 comet-ml/opik 的OpenRank趋势数据\n",
      "成功获取 dagger/dagger 的OpenRank趋势数据\n",
      "成功获取 pipecat-ai/pipecat 的OpenRank趋势数据\n",
      "成功获取 HKUDS/LightRAG 的OpenRank趋势数据\n",
      "成功获取 InternLM/lmdeploy 的OpenRank趋势数据\n",
      "成功获取 sst/opencode 的OpenRank趋势数据\n",
      "成功获取 AstrBotDevs/AstrBot 的OpenRank趋势数据\n",
      "成功获取 Genesis-Embodied-AI/Genesis 的OpenRank趋势数据\n",
      "成功获取 qdrant/qdrant 的OpenRank趋势数据\n",
      "成功获取 keras-team/keras 的OpenRank趋势数据\n",
      "成功获取 docling-project/docling 的OpenRank趋势数据\n",
      "成功获取 opea-project/GenAIExamples 的OpenRank趋势数据\n",
      "成功获取 activepieces/activepieces 的OpenRank趋势数据\n",
      "成功获取 Arize-ai/phoenix 的OpenRank趋势数据\n",
      "成功获取 langchain4j/langchain4j 的OpenRank趋势数据\n",
      "成功获取 deepspeedai/DeepSpeed 的OpenRank趋势数据\n",
      "成功获取 mlrun/mlrun 的OpenRank趋势数据\n",
      "成功获取 bytedance/deer-flow 的OpenRank趋势数据\n",
      "成功获取 vllm-project/vllm-ascend 的OpenRank趋势数据\n",
      "成功获取 invoke-ai/InvokeAI 的OpenRank趋势数据\n",
      "成功获取 cvat-ai/cvat 的OpenRank趋势数据\n",
      "成功获取 vespa-engine/vespa 的OpenRank趋势数据\n",
      "成功获取 pytorch/torchtune 的OpenRank趋势数据\n",
      "成功获取 FlowiseAI/Flowise 的OpenRank趋势数据\n",
      "成功获取 NVIDIA/TransformerEngine 的OpenRank趋势数据\n",
      "成功获取 gpustack/gpustack 的OpenRank趋势数据\n",
      "成功获取 onyx-dot-app/onyx 的OpenRank趋势数据\n",
      "成功获取 containers/ramalama 的OpenRank趋势数据\n",
      "成功获取 FunAudioLLM/CosyVoice 的OpenRank趋势数据\n",
      "成功获取 promptfoo/promptfoo 的OpenRank趋势数据\n",
      "成功获取 dust-tt/dust 的OpenRank趋势数据\n",
      "成功获取 pytorch/xla 的OpenRank趋势数据\n",
      "成功获取 Kong/kong 的OpenRank趋势数据\n",
      "成功获取 mem0ai/mem0 的OpenRank趋势数据\n",
      "成功获取 Dao-AILab/flash-attention 的OpenRank趋势数据\n",
      "成功获取 deepflowio/deepflow 的OpenRank趋势数据\n",
      "成功获取 volcano-sh/volcano 的OpenRank趋势数据\n",
      "成功获取 flashinfer-ai/flashinfer 的OpenRank趋势数据\n",
      "成功获取 Unstructured-IO/unstructured 的OpenRank趋势数据\n",
      "成功获取 searxng/searxng 的OpenRank趋势数据\n",
      "成功获取 ComposioHQ/composio 的OpenRank趋势数据\n",
      "成功获取 zenml-io/zenml 的OpenRank趋势数据\n",
      "成功获取 Significant-Gravitas/AutoGPT 的OpenRank趋势数据\n",
      "成功获取 bentoml/BentoML 的OpenRank趋势数据\n",
      "成功获取 qodo-ai/pr-agent 的OpenRank趋势数据\n",
      "成功获取 songquanpeng/one-api 的OpenRank趋势数据\n",
      "成功获取 SillyTavern/SillyTavern 的OpenRank趋势数据\n",
      "成功获取 deepset-ai/haystack 的OpenRank趋势数据\n",
      "成功获取 mlc-ai/mlc-llm 的OpenRank趋势数据\n",
      "成功获取 ChatGPTNextWeb/NextChat 的OpenRank趋势数据\n",
      "成功获取 dask/dask 的OpenRank趋势数据\n",
      "成功获取 lancedb/lancedb 的OpenRank趋势数据\n",
      "成功获取 OpenRLHF/OpenRLHF 的OpenRank趋势数据\n",
      "成功获取 hpcaitech/ColossalAI 的OpenRank趋势数据\n",
      "成功获取 microsoft/graphrag 的OpenRank趋势数据\n",
      "成功获取 NVIDIA/nccl 的OpenRank趋势数据\n",
      "成功获取 huggingface/text-generation-inference 的OpenRank趋势数据\n",
      "成功获取 letta-ai/letta 的OpenRank趋势数据\n",
      "成功获取 AUTOMATIC1111/stable-diffusion-webui 的OpenRank趋势数据\n",
      "成功获取 lm-sys/FastChat 的OpenRank趋势数据\n",
      "成功获取 NVIDIA/cutlass 的OpenRank趋势数据\n",
      "成功获取 kserve/kserve 的OpenRank趋势数据\n",
      "成功获取 kvcache-ai/Mooncake 的OpenRank趋势数据\n",
      "成功获取 NVIDIA/Megatron-LM 的OpenRank趋势数据\n",
      "成功获取 dagster-io/dagster 的OpenRank趋势数据\n",
      "成功获取 google/A2A 的OpenRank趋势数据\n",
      "成功获取 flyteorg/flyte 的OpenRank趋势数据\n",
      "成功获取 dbt-labs/dbt-core 的OpenRank趋势数据\n",
      "成功获取 camel-ai/owl 的OpenRank趋势数据\n",
      "成功获取 open-compass/opencompass 的OpenRank趋势数据\n",
      "成功获取 mem0ai/mem0 的OpenRank趋势数据\n",
      "成功获取 FoundationAgents/MetaGPT 的OpenRank趋势数据\n",
      "成功获取 Farama-Foundation/Gymnasium 的OpenRank趋势数据\n",
      "成功获取 ItzCrazyKns/Perplexica 的OpenRank趋势数据\n",
      "成功获取 ml-explore/mlx 的OpenRank趋势数据\n",
      "成功获取 TabbyML/tabby 的OpenRank趋势数据\n",
      "成功获取 pgvector/pgvector 的OpenRank趋势数据\n",
      "成功获取 microsoft/OmniParser 的OpenRank趋势数据\n",
      "成功获取 triton-inference-server/server 的OpenRank趋势数据\n",
      "成功获取 chatboxai/chatbox 的OpenRank趋势数据\n",
      "成功获取 iterative/datachain 的OpenRank趋势数据\n",
      "成功获取 deepseek-ai/DeepEP 的OpenRank趋势数据\n",
      "成功获取 Zipstack/unstract 的OpenRank趋势数据\n",
      "成功获取 chatchat-space/Langchain-Chatchat 的OpenRank趋势数据\n",
      "成功获取 zaidmukaddam/scira 的OpenRank趋势数据\n",
      "成功获取 mindverse/Second-Me 的OpenRank趋势数据\n",
      "成功获取 vllm-project/aibrix 的OpenRank趋势数据\n",
      "成功获取 eosphoros-ai/DB-GPT 的OpenRank趋势数据\n",
      "成功获取 nomic-ai/gpt4all 的OpenRank趋势数据\n",
      "成功获取 oobabooga/text-generation-webui 的OpenRank趋势数据\n",
      "成功获取 Netflix/metaflow 的OpenRank趋势数据\n",
      "成功获取 unitycatalog/unitycatalog 的OpenRank趋势数据\n",
      "成功获取 elastic/elasticsearch 的OpenRank趋势数据\n",
      "已完成所有仓库的OpenRank趋势数据获取和保存\n"
     ]
    }
   ],
   "source": [
    "# 读取 repository_data.csv 并获取 OpenRank 趋势数据\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "# 读取 repository_data.csv\n",
    "df = pd.read_csv('repository_data.csv')\n",
    "\n",
    "# 遍历每个仓库获取 OpenRank 数据\n",
    "for idx, row in df.iterrows():\n",
    "    repo_name = row['repo_name']\n",
    "    url = f\"https://oss.open-digger.cn/github/{repo_name}/openrank.json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # 提取2025年的月度数据\n",
    "            trends = []\n",
    "            for month in range(1, 13):\n",
    "                month_key = f\"2025-{month:02d}\"\n",
    "                if month_key in data:\n",
    "                    trends.append(round(data[month_key]))\n",
    "            \n",
    "            # 将趋势数据保存到DataFrame中\n",
    "            df.at[idx, 'trends'] = str(trends)\n",
    "            \n",
    "            print(f\"成功获取 {repo_name} 的OpenRank趋势数据\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"获取 {repo_name} 数据失败: {response.status_code}\")\n",
    "            df.at[idx, 'trends'] = '[]'\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"处理 {repo_name} 时发生错误: {str(e)}\")\n",
    "        df.at[idx, 'trends'] = '[]'\n",
    "\n",
    "# 保存更新后的数据\n",
    "df.to_csv('repository_data.csv', index=False)\n",
    "print(\"已完成所有仓库的OpenRank趋势数据获取和保存\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import clickhouse_connect\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "clickhouse_host = os.getenv(\"CLICKHOUSE_HOST\")\n",
    "username = os.getenv(\"CLICKHOUSE_USER\")\n",
    "password = os.getenv(\"CLICKHOUSE_PASSWORD\")\n",
    "github_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "client = clickhouse_connect.get_client(host=clickhouse_host, port=8123, username=username, password=password)\n",
    "\n",
    "headers = {\n",
    "  \"Authorization\": f\"token {github_token}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search most related projects\n",
    "def search_projects(project_ids, limit):\n",
    "    sql_search_projects = \"\"\"\n",
    "    WITH\n",
    "        -- 获取仓库在指定时间段内的活跃开发者\n",
    "        active_developers AS (\n",
    "            SELECT DISTINCT actor_id, repo_id, repo_name\n",
    "            FROM opensource.events\n",
    "            WHERE repo_id IN (%s)\n",
    "            AND (type IN ('IssuesEvent', 'PullRequestEvent', 'IssueCommentEvent', 'PullRequestReviewEvent','PullRequestReviewCommentEvent'))\n",
    "        ),\n",
    "        -- 计算其他仓库中的活跃开发者\n",
    "        repo_activity AS (\n",
    "            SELECT repo_id, repo_name, COUNT(DISTINCT actor_id) AS active_count\n",
    "            FROM opensource.events\n",
    "            WHERE actor_id IN (SELECT actor_id FROM active_developers)\n",
    "            AND repo_id NOT IN (%s)\n",
    "            AND (type IN ('IssuesEvent', 'PullRequestEvent', 'IssueCommentEvent','PullRequestReviewEvent', 'PullRequestReviewCommentEvent'))\n",
    "            GROUP BY repo_id, repo_name\n",
    "        )\n",
    "        -- 获取关联度最高的 x 个仓库\n",
    "        SELECT repo_id, repo_name, active_count\n",
    "        FROM repo_activity\n",
    "        ORDER BY active_count DESC\n",
    "        LIMIT %s\n",
    "        \"\"\"\n",
    "    formatted_query = sql_search_projects % (', '.join(f\"'{id}'\" for id in project_ids), ', '.join(f\"'{id}'\" for id in project_ids), limit)\n",
    "    results = client.query(formatted_query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch repo_name and avg OpenRank 25 from clickhouse\n",
    "def execute_repo_details(repo_id):\n",
    "  sql_query = \"\"\"\n",
    "    -- 根据 repo_id 查询最新的 repo_name 和 openrank 均值\n",
    "    WITH latest_repo_name AS (\n",
    "      SELECT repo_id, repo_name\n",
    "      FROM opensource.events\n",
    "      WHERE repo_id = %s\n",
    "      ORDER BY created_at DESC\n",
    "      LIMIT 1\n",
    "    ),\n",
    "    avg_openrank AS (\n",
    "      SELECT repo_id, ROUND(avg(openrank), 0) AS average_openrank\n",
    "      FROM opensource.global_openrank\n",
    "      WHERE repo_id = %s\n",
    "      AND platform = 'GitHub'\n",
    "      AND created_at >= '2025-01-01'\n",
    "      AND created_at < '2026-01-01'\n",
    "      GROUP BY repo_id\n",
    "    )\n",
    "    SELECT n.repo_id, n.repo_name, o.average_openrank\n",
    "    FROM latest_repo_name n\n",
    "    JOIN avg_openrank o ON n.repo_id = o.repo_id\n",
    "  \"\"\"\n",
    "  formatted_query = sql_query % (f\"'{repo_id}'\", f\"'{repo_id}'\")\n",
    "  results = client.query(formatted_query)\n",
    "  return results.result_rows\n",
    "\n",
    "# fetch stars and descripiton through repo_name\n",
    "def fetch_repo_info(repo_names, headers):\n",
    "  github_repo_url = \"https://api.github.com/repos/\"\n",
    "  repo_data = []\n",
    "\n",
    "  for repo_name in repo_names:\n",
    "    response = requests.get(github_repo_url + repo_name, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "      data = response.json()\n",
    "      repo_id = data['id']\n",
    "      stars = data['stargazers_count']\n",
    "      description = data['description']\n",
    "      repo_data.append({'repo_name': repo_name, 'stars': stars, 'description': description, 'repo_id': repo_id})\n",
    "    else:\n",
    "      print(f\"Failed to fetch data for {repo_name}\")\n",
    "  \n",
    "  return repo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the initial repositories from the CSV file\n",
    "initial_repos = pd.read_csv('initial_repos.csv')\n",
    "iter1_repos = pd.read_csv('iter1_repos.csv')\n",
    "iter2_repos = pd.read_csv('iter2_repos.csv')\n",
    "\n",
    "# repo_id_full\n",
    "repo_id_full = list(set(initial_repos['repo_id'].tolist() + iter1_repos['repo_id'].tolist() + iter2_repos['repo_id'].tolist()))\n",
    "\n",
    "repo_ids = iter2_repos['repo_id'].tolist()\n",
    "\n",
    "projects = set()\n",
    "for repo_id in repo_ids:\n",
    "    results = execute_search_projects([repo_id], 5)\n",
    "    for row in results.result_rows:\n",
    "        projects.add (row[0])\n",
    "projects = list(projects)\n",
    "\n",
    "unique_projects_ids = list(set(projects) - set(repo_id_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
